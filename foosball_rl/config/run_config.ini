[Common]
experiment_name : TestRunPPOv4
# Possible values: train, test
mode : train
# Possible values: Foosball-v0, Goalkeeper-v0
env_id: Goalkeeper-v0

[Wrapper]
# Action space (discrete, multi-discrete, continuous)
action_space : continuous
# Binning parameters for (multi-)discrete action space
lateral_bins : 5
angular_bins : 5

[Algorithm]
policy : MlpPolicy
discount_factor : 0.99
# See SB3 documentation for available options and train.py for additional implementation requirements
;policy_kwargs : {'net_arch':{'pi':[64, 64], 'vf':[64, 64]}}

[Training]
seeds: [1, 2, 3, 4, 5]
total_timesteps : 500000
tb_log_name : training_run

[Testing]
eval_seed : 1
test_model_path: model/to/test/model.zip
normalized_env_path: model/to/test/env_rms.pkl
num_eval_episodes : 100

[Callbacks]
save_freq : 250000
save_replay_buffer : True
save_vecnormalize : True

[VideoRecording]
# Works only if render_mode == 'rgb_array', doesn't support human rendering and recording
record_videos : True
video_interval : 250000
video_length : 1000
video_log_path_suffix : videos
