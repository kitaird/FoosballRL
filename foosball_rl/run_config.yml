Common:
    experiment_name : TestRun
    # Possible values: train, test
    mode : train
    # Possible values: Foosball-v0, Goalkeeper-v0
    env_id : Goalkeeper-v0
    # Possible values: a2c, ddpg, dqn, ppo, sac, td3, ars, qrdqn, tqc, trpo, ppo_lstm
    algorithm : ppo

Wrapper:
    # Turn this on if you want to use Hindsight Experience Replay (HerReplayBuffer), you must still specify HER in the algorithm's hyperparameters
    use_goal_env_wrapper : False
    # Action space (discrete, multi-discrete, continuous)
    action_space : continuous
    # Binning parameters for (multi-)discrete action space
    lateral_bins : 5
    angular_bins : 5

Training:
    seeds : [100, 200, 300]
    n_envs : 1
    total_timesteps : !!float 1.5e6
    tb_log_name : training_run
    vec_normalize_load_path : null

Testing:
    eval_seed : 1
    n_envs : 1
    model_path : experiments/TestRun/training/seed-100/eval/best/best_model.zip
    vec_normalize_load_path : experiments/TestRun/training/seed-100/eval/best/vecnormalize.pkl
    num_eval_episodes : 100

Callbacks:
    use_eval_callback: False
    EvalCallback:
        eval_n_envs: 1
        eval_seed: 10
        eval_n_episodes: 25
        eval_freq: !!float 1e5
        eval_deterministic: True
    use_checkpoint_callback: False
    CheckpointCallback:
        checkpoint_save_freq: !!float 5e4
        checkpoint_save_replay_buffer: True
        checkpoint_save_vecnormalize: True
    use_progress_bar_callback: True

VideoRecording:
    # Works only if the environment render_mode == 'rgb_array', doesn't support human rendering and recording
    record_videos : False
    video_interval : !!float 2e5
    video_length : 1000
    video_log_path_suffix : videos
